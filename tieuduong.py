# =============================================================================
# Dá»° ÄOÃN Bá»†NH TIá»‚U ÄÆ¯á»œNG Sá»¬ Dá»¤NG Máº NG NÆ -RON NHÃ‚N Táº O (ANN)
# =============================================================================

# --- BÆ°á»›c 1: Gá»i cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t ---
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# --- BÆ°á»›c 2: Táº£i vÃ  chuáº©n bá»‹ dá»¯ liá»‡u ---
print(">>> BÆ°á»›c 2: Äang táº£i vÃ  chuáº©n bá»‹ dá»¯ liá»‡u...")

# Táº£i táº­p dá»¯ liá»‡u Pima Indians Diabetes Dataset tá»« URL
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
columns = [
    "Pregnancies", "Glucose", "BloodPressure", "SkinThickness", "Insulin", 
    "BMI", "DiabetesPedigreeFunction", "Age", "Outcome"
]
df = pd.read_csv(url, names=columns)

# Xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ 0 khÃ´ng há»£p lá»‡, thay tháº¿ báº±ng giÃ¡ trá»‹ trung bÃ¬nh cá»§a cá»™t
# ÄÃ¢y lÃ  má»™t bÆ°á»›c quan trá»ng Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh
cols_to_replace = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
for col in cols_to_replace:
    # Thay tháº¿ 0 báº±ng giÃ¡ trá»‹ NA (Not Available) Ä‘á»ƒ tÃ­nh toÃ¡n
    df[col].replace(0, pd.NA, inplace=True)
    # TÃ­nh giÃ¡ trá»‹ trung bÃ¬nh (bá» qua cÃ¡c giÃ¡ trá»‹ NA)
    mean_val = df[col].mean()
    # Äiá»n giÃ¡ trá»‹ trung bÃ¬nh vÃ o cÃ¡c Ã´ bá»‹ thiáº¿u (NA)
    df[col].fillna(mean_val, inplace=True)

# TÃ¡ch biáº¿n Ä‘áº§u vÃ o (X - features) vÃ  biáº¿n má»¥c tiÃªu (y - target)
X = df.drop('Outcome', axis=1)
y = df['Outcome']

# --- BÆ°á»›c 3: Chia vÃ  chuáº©n hÃ³a dá»¯ liá»‡u ---
print(">>> BÆ°á»›c 3: Äang chia vÃ  chuáº©n hÃ³a dá»¯ liá»‡u...")

# Chia dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n (80%) vÃ  táº­p kiá»ƒm tra (20%)
# stratify=y Ä‘á»ƒ Ä‘áº£m báº£o tá»· lá»‡ outcome trong táº­p train vÃ  test lÃ  tÆ°Æ¡ng Ä‘á»“ng
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Chuáº©n hÃ³a dá»¯ liá»‡u: ÄÆ°a táº¥t cáº£ cÃ¡c feature vá» cÃ¹ng má»™t thang Ä‘o
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# --- BÆ°á»›c 4: XÃ¢y dá»±ng mÃ´ hÃ¬nh Máº¡ng NÆ¡-ron (ANN) ---
print(">>> BÆ°á»›c 4: Äang xÃ¢y dá»±ng mÃ´ hÃ¬nh ANN...")

model = Sequential()
model.add(Dense(12, activation='relu', input_shape=(X_train.shape[1],))) # Lá»›p vÃ o vÃ  lá»›p áº©n 1
model.add(Dense(8, activation='relu'))                                  # Lá»›p áº©n 2
model.add(Dense(1, activation='sigmoid'))                               # Lá»›p ra (cho bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n)

# In ra cáº¥u trÃºc cá»§a mÃ´ hÃ¬nh
print("\nâœ… Cáº¥u trÃºc mÃ´ hÃ¬nh ANN:")
model.summary()
print("-" * 40)

# BiÃªn dá»‹ch mÃ´ hÃ¬nh
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# --- BÆ°á»›c 5: Huáº¥n luyá»‡n mÃ´ hÃ¬nh ---
print(">>> BÆ°á»›c 5: Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ´ hÃ¬nh...")

# Huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i dá»¯ liá»‡u training
# verbose=1 Ä‘á»ƒ hiá»ƒn thá»‹ thanh tiáº¿n trÃ¬nh cho má»—i epoch
history = model.fit(X_train, y_train,
                    validation_data=(X_test, y_test),
                    epochs=50,
                    verbose=1)

print("\nâœ… HoÃ n táº¥t huáº¥n luyá»‡n!")
print("-" * 40)

# --- BÆ°á»›c 6: ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh ---
print(">>> BÆ°á»›c 6: ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t mÃ´ hÃ¬nh...")

# ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u kiá»ƒm tra
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f'ğŸ“Š Äá»™ máº¥t mÃ¡t trÃªn táº­p kiá»ƒm tra (Loss): {loss:.4f}')
print(f'ğŸ¯ Äá»™ chÃ­nh xÃ¡c trÃªn táº­p kiá»ƒm tra (Accuracy): {accuracy*100:.2f}%')
print("-" * 40)